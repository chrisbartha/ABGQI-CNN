{"cells":[{"cell_type":"markdown","metadata":{"id":"h5ZL0YYBQh31"},"source":["# Train CNN on ABG data wihtout prior XC training\n","- You will need to provide training and validation data to run this script.\n","- Uses env ABG-cnn_tf230"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":103},"id":"dD2bYAiEQh34","executionInfo":{"status":"ok","timestamp":1699554872252,"user_tz":480,"elapsed":36205,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}},"outputId":"962e2b62-9d74-45c5-b5ec-ef24de797e8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/CQuinn8-ABGQI-CNN-93420d1/1_cnn_training-py/code\n","env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n","env: CUDA_VISIBLE_DEVICES=1\n"]},{"output_type":"execute_result","data":{"text/plain":["'2.14.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["import tensorflow as tf\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd ~/../content/drive/MyDrive/Colab\\ Notebooks/CQuinn8-ABGQI-CNN-93420d1/1_cnn_training-py/code\n","\n","%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n","%env CUDA_VISIBLE_DEVICES=1\n","\n","import IPython.display as display\n","from PIL import Image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import pathlib\n","\n","# option to not use GPUs\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n","\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","tf.__version__"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZqmyZQN3Qh35","executionInfo":{"status":"ok","timestamp":1699554872252,"user_tz":480,"elapsed":13,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}},"outputId":"2aa55d92-ebad-48ee-998c-3ec97358b3bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available:  0\n"]}],"source":["print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bgwmoJNbQh35","executionInfo":{"status":"ok","timestamp":1699554873554,"user_tz":480,"elapsed":1309,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}},"outputId":"40a5fbc7-d7c2-411b-e8db-e22b486eb6eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["does this checkpoint exist?\n","../results/ABGQI-CNN/cp.ckpt\n"]},{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":3}],"source":["# MODEL OUTPUT PATH\n","# Let's checkpoint the model here when needed\n","checkpoint_path = '../results/ABGQI-CNN/cp.ckpt'\n","print(\"does this checkpoint exist?\")\n","print(checkpoint_path)\n","os.path.isfile(checkpoint_path)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"kWOQw0frQh36","executionInfo":{"status":"ok","timestamp":1699554873554,"user_tz":480,"elapsed":2,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# INPUT DATA\n","# Set up training data\n","tr_pth = '../data/splits/training'\n","data_dir = pathlib.Path(tr_pth)\n","\n","# Set up the validation data\n","val_pth = '../data/splits/validation'\n","val_data_dir = pathlib.Path(val_pth)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"qRSOd37VQh36","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699554891020,"user_tz":480,"elapsed":17467,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}},"outputId":"57f6819f-362d-4b27-ae63-89c29ce7a381"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n","WARNING:absl:`mobilenetv2_1.40_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_40_224_input`.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," mobilenetv2_1.40_224 (Func  (None, 7, 7, 1792)        4363712   \n"," tional)                                                         \n","                                                                 \n"," global_average_pooling2d (  (None, 1792)              0         \n"," GlobalAveragePooling2D)                                         \n","                                                                 \n"," dense (Dense)               (None, 54)                96822     \n","                                                                 \n","=================================================================\n","Total params: 4460534 (17.02 MB)\n","Trainable params: 4318198 (16.47 MB)\n","Non-trainable params: 142336 (556.00 KB)\n","_________________________________________________________________\n"]}],"source":["# PRETRAINED MODEL INPUT\n","# MobNet pretrained on imagenet\n","model_path = '../data/IMGNET_mobileNet_S2L_finetune/my_model/'\n","new_model = tf.keras.models.load_model(model_path)\n","new_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"qJWTZ0JbQh36"},"source":["### Functions"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"7chXRAbXQh37","executionInfo":{"status":"ok","timestamp":1699554891020,"user_tz":480,"elapsed":18,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["def get_label(file_path):\n","  # convert the path to a list of path components\n","  parts = tf.strings.split(file_path, os.path.sep)\n","  # The second to last is the class-directory\n","  return parts[-2] == CLASS_NAMES\n","\n","def decode_img(img):\n","  # convert the compressed string to a 3D uint8 tensor\n","  img = tf.image.decode_jpeg(img, channels=3)\n","  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n","  img = tf.image.convert_image_dtype(img, tf.float32)\n","  # resize the image to the desired size.\n","  return tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n","\n","def process_path(file_path):\n","    label = get_label(file_path)\n","    # load the raw data from the file as a string\n","    img = tf.io.read_file(file_path)\n","    img = decode_img(img)\n","    return img, label"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"lrsxDjcKQh37","executionInfo":{"status":"ok","timestamp":1699554891020,"user_tz":480,"elapsed":16,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000, repeat=1):\n","  # This is a small dataset, only load it once, and keep it in memory.\n","  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n","  # fit in memory.\n","  if cache:\n","    if isinstance(cache, str):\n","        ds = ds.cache(cache)\n","    else:\n","        ds = ds.cache()\n","\n","  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n","\n","  # Repeat forever\n","  ds = ds.repeat(repeat)     # repeat has arg 'count' = A tf.int64 scalar tf.Tensor, representing the number of times the dataset should be repeated. The default behavior (if count is None or -1) is for the dataset be repeated indefinitely.\n","\n","  ds = ds.batch(BATCH_SIZE)\n","\n","  # `prefetch` lets the dataset fetch batches in the background while the model\n","  # is training.\n","  ds = ds.prefetch(buffer_size=AUTOTUNE)\n","\n","  return ds\n","\n","def show_batch(image_batch, label_batch):\n","  plt.figure(figsize=(10,10))\n","  for n in range(25):\n","      ax = plt.subplot(5,5,n+1)\n","      plt.imshow(image_batch[n])\n","      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n","      plt.axis('off')"]},{"cell_type":"markdown","metadata":{"id":"M1oyQiyuQh38"},"source":["### Image analysis"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"i9LLrPNyQh38","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699554891020,"user_tz":480,"elapsed":15,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}},"outputId":"37cd2b8d-a908-4fff-a99d-8e3c3b0af104"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":8}],"source":["image_count = len(list(data_dir.glob('*/*.png')))\n","image_count"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"LnAWPHpHQh38","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699554891020,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}},"outputId":"32adb455-42a6-4fc2-8820-6c972067aba9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([], dtype=float64)"]},"metadata":{},"execution_count":9}],"source":["CLASS_NAMES = np.array([item.name for item in data_dir.glob('*')])\n","CLASS_NAMES"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"v8CSTW75Qh39","executionInfo":{"status":"ok","timestamp":1699554891020,"user_tz":480,"elapsed":4,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# The 1./255 is to convert from uint8 to float32 in range [0,1].\n","image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"QtJH2KXgQh39","executionInfo":{"status":"ok","timestamp":1699554891020,"user_tz":480,"elapsed":4,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# training parameters\n","BATCH_SIZE = 64\n","IMG_HEIGHT = 224\n","IMG_WIDTH = 224\n","STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"C64eIWBeQh39","colab":{"base_uri":"https://localhost:8080/","height":385},"executionInfo":{"status":"error","timestamp":1699554891876,"user_tz":480,"elapsed":859,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}},"outputId":"ea6e3731-438c-4125-a8d8-2efb6160e4be"},"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-68e28feb1726>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# example of 5 pngs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlist_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'*/*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mlist_files\u001b[0;34m(file_pattern, shuffle, seed, name)\u001b[0m\n\u001b[1;32m   1291\u001b[0m           string_ops.reduce_join(file_pattern, separator=\", \"), name=\"message\")\n\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m       assert_not_empty = control_flow_assert.Assert(\n\u001b[0m\u001b[1;32m   1294\u001b[0m           condition, [message], summarize=1, name=\"assert_not_empty\")\n\u001b[1;32m   1295\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massert_not_empty\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/control_flow_assert.py\u001b[0m in \u001b[0;36mAssert\u001b[0;34m(condition, data, summarize, name)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_n_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mdata_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_summarize_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m       raise errors.InvalidArgumentError(\n\u001b[0m\u001b[1;32m    103\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: ../data/splits/training/*/*'"]}],"source":["# example of 5 pngs\n","list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\n","for f in list_ds.take(5):\n","    print(f.numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wsI_mn8HQh3-","executionInfo":{"status":"aborted","timestamp":1699554891876,"user_tz":480,"elapsed":13,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n","labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CfTPkqCQQh3-","executionInfo":{"status":"aborted","timestamp":1699554891876,"user_tz":480,"elapsed":13,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# what are the dimensions of a png and what do the labels look like\n","for image, label in labeled_ds.take(1):\n","    print(\"Image shape: \", image.numpy().shape)\n","    print(\"Label: \", label.numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X5fiXzQaQh3-","executionInfo":{"status":"aborted","timestamp":1699554891877,"user_tz":480,"elapsed":14,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# Prep dataset iterations\n","train_ds = prepare_for_training(labeled_ds, repeat = None)\n","image_batch, label_batch = next(iter(train_ds))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"09IGH24ZQh3-","executionInfo":{"status":"aborted","timestamp":1699554891877,"user_tz":480,"elapsed":14,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# display some pngs\n","show_batch(image_batch.numpy(), label_batch.numpy())"]},{"cell_type":"markdown","metadata":{"id":"SG2j1tTsQh3_"},"source":["#### Validation data\n","- follows the same preparation as training data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"96D9E3WBQh3_","executionInfo":{"status":"aborted","timestamp":1699554891877,"user_tz":480,"elapsed":13,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["val_image_count = len(list(val_data_dir.glob('*/*.png')))\n","val_image_count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qdrtEha_Qh3_","executionInfo":{"status":"aborted","timestamp":1699554891877,"user_tz":480,"elapsed":13,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["val_data_dir"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_l7poh2xQh4A","executionInfo":{"status":"aborted","timestamp":1699554891877,"user_tz":480,"elapsed":13,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["CLASS_NAMES = np.array([item.name for item in val_data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n","CLASS_NAMES"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eMmDW_g7Qh4A","executionInfo":{"status":"aborted","timestamp":1699554891877,"user_tz":480,"elapsed":12,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# The 1./255 is to convert from uint8 to float32 in range [0,1].\n","image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dcyMG1ivQh4A","executionInfo":{"status":"aborted","timestamp":1699554891877,"user_tz":480,"elapsed":12,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["STEPS_PER_EPOCH = np.ceil(val_image_count/BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D1DlbF7jQh4A","executionInfo":{"status":"aborted","timestamp":1699554891877,"user_tz":480,"elapsed":12,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["list_ds = tf.data.Dataset.list_files(str(val_data_dir/'*/*'))\n","\n","for f in list_ds.take(5):\n","    print(f.numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gOaHiTtHQh4B","executionInfo":{"status":"aborted","timestamp":1699554891877,"user_tz":480,"elapsed":12,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n","labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oaHKvBFfQh4B","executionInfo":{"status":"aborted","timestamp":1699554891877,"user_tz":480,"elapsed":11,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["for image, label in labeled_ds.take(1):\n","    print(\"Image shape: \", image.numpy().shape)\n","    print(\"Label: \", label.numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CaMbAQqdQh4B","executionInfo":{"status":"aborted","timestamp":1699554891877,"user_tz":480,"elapsed":11,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["validation_ds = prepare_for_training(labeled_ds)\n","image_batch, label_batch = next(iter(validation_ds))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ku_wCOgyQh4B","executionInfo":{"status":"aborted","timestamp":1699554891877,"user_tz":480,"elapsed":11,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["show_batch(image_batch.numpy(), label_batch.numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vEUsYwpdQh4C","executionInfo":{"status":"aborted","timestamp":1699554891877,"user_tz":480,"elapsed":10,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# NOW WE HAVE:\n","print(validation_ds)\n","print(train_ds)"]},{"cell_type":"markdown","metadata":{"id":"qGZfN65oQh4C"},"source":["## MODEL TRAINING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2qn1JnLbQh4C","executionInfo":{"status":"aborted","timestamp":1699554891878,"user_tz":480,"elapsed":11,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# Image size, here 224 is default MobileNet x, y with 3 bands (RGB)\n","IMG_SIZE = 224\n","IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1WMY2t4Qh4C","executionInfo":{"status":"aborted","timestamp":1699554891878,"user_tz":480,"elapsed":11,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# number of target class : ABGIQ\n","n_classes = len(CLASS_NAMES)\n","print(n_classes)\n","print(CLASS_NAMES)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sa2ERBGVQh4C","executionInfo":{"status":"aborted","timestamp":1699554891878,"user_tz":480,"elapsed":10,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# Remove FC and Global pooling layers to allow for ABGQI fine tuning\n","base_model_output = new_model.layers[-3]#.output\n","print(base_model_output)\n","feature_batch = base_model_output(image_batch)\n","\n","base_model_output.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hyeu_IKuQh4C","executionInfo":{"status":"aborted","timestamp":1699554891878,"user_tz":480,"elapsed":10,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# Add pooling layer\n","global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n","feature_batch_average = global_average_layer(feature_batch)\n","print(feature_batch_average.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jemcndwzQh4C","executionInfo":{"status":"aborted","timestamp":1699554891878,"user_tz":480,"elapsed":10,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# Add FC/ Dense layer\n","prediction_layer = tf.keras.layers.Dense(n_classes, activation = None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSe4RSFsQh4C","executionInfo":{"status":"aborted","timestamp":1699554891878,"user_tz":480,"elapsed":10,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# compile the new model with S2L-mobilenet weights and new pooling + FC layers\n","model = tf.keras.Sequential([\n","  base_model_output,\n","  global_average_layer,\n","  prediction_layer\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZYhznK7aQh4D","executionInfo":{"status":"aborted","timestamp":1699554891878,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# Let's take a look to see how many layers are in the base model (i.e. S2L pre-trained mobileNet)\n","print(\"Number of layers in the base model: \", len(base_model_output.layers))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tn87FcxGQh4D","executionInfo":{"status":"aborted","timestamp":1699554891878,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# Fine tune FC layers\n","base_learning_rate = 0.0001 #the initial learning rate. This will be reduced by a factor of 10 in the Finetuning stage\n","\n","# specify what loss function, optimizer, and accuracy metric to use\n","model.compile(optimizer = tf.keras.optimizers.Adam(lr=base_learning_rate),\n","              metrics=tf.keras.metrics.CategoricalAccuracy(),\n","              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)) #Whether to interpret y_pred as a tensor of logit values. By default, we assume that y_pred contains probabilities (i.e., values in [0, 1]). **Note - Using from_logits=True may be more numerically stable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qMW69riZQh4D","executionInfo":{"status":"aborted","timestamp":1699554891878,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["model.summary() # trainable params = 8,965 here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AVpH84lzQh4E","executionInfo":{"status":"aborted","timestamp":1699554891878,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["len(model.trainable_variables) # pooling and dense layers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kwqmWs0vQh4E","executionInfo":{"status":"aborted","timestamp":1699554891878,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# NOW USE THE validation_ds and train_ds THAT WE BUILT BEFORE\n","loss0,accuracy0 = model.evaluate(validation_ds, steps= val_image_count // BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kh0_7mcnQh4E","executionInfo":{"status":"aborted","timestamp":1699554891879,"user_tz":480,"elapsed":10,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["print(\"initial loss: {:.2f}\".format(loss0))\n","print(\"initial accuracy: {:.2f}\".format(accuracy0))"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"VQteUHctQh4E","executionInfo":{"status":"aborted","timestamp":1699554891879,"user_tz":480,"elapsed":10,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# train with our prepared data\n","initial_epochs = 10 # short training period\n","history = model.fit(train_ds,\n","                    epochs=initial_epochs,\n","                    validation_data=validation_ds,\n","                    steps_per_epoch = np.ceil(image_count/BATCH_SIZE))"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"hvKOINmCQh4E","executionInfo":{"status":"aborted","timestamp":1699554891879,"user_tz":480,"elapsed":10,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# visualize accuracy and loss\n","acc = history.history['categorical_accuracy']\n","val_acc = history.history['val_categorical_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.ylabel('Accuracy')\n","plt.ylim([min(plt.ylim()),1])\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.ylabel('Cross Entropy')\n","plt.ylim([0,1.0])\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"T28LJg7-Qh4E"},"source":["### MODEL TRAINING: fine tuning the base model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nCiXz_h6Qh4F","executionInfo":{"status":"aborted","timestamp":1699554891879,"user_tz":480,"elapsed":10,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# update the ability to train th mobilenet base\n","base_model_output.trainable = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7C4va-HtQh4F","executionInfo":{"status":"aborted","timestamp":1699554891879,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# Let's take a look to see how many layers are in the base model\n","print(\"Number of layers in the base model: \", len(base_model_output.layers))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGlEIbiaQh4F","executionInfo":{"status":"aborted","timestamp":1699554891879,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# Train CNN features here\n","# Fine-tune from this layer onwards\n","fine_tune_at = 50\n","\n","# Freeze all the layers before the `fine_tune_at` layer\n","for layer in base_model_output.layers[:fine_tune_at]:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NSoO-W4jQh4F","executionInfo":{"status":"aborted","timestamp":1699554891879,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# reduce learning rate by factor of ten\n","second_tr_lr = base_learning_rate/10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ukt0SKp7Qh4F","executionInfo":{"status":"aborted","timestamp":1699554891879,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# set up model but with second learning rate\n","model.compile(optimizer = tf.keras.optimizers.Adam(lr=second_tr_lr),     # reduce lr by a factor of 10! LR is 0.00001 here then\n","              metrics=tf.keras.metrics.CategoricalAccuracy(),\n","              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xe82391BQh4F","executionInfo":{"status":"aborted","timestamp":1699554891879,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XAF9CC-dQh4F","executionInfo":{"status":"aborted","timestamp":1699554891879,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["len(model.trainable_variables) # more trainable parameters because we are tuning the base mobilenet now"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TNEdtzaVQh4G","executionInfo":{"status":"aborted","timestamp":1699554891879,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["fine_tune_epochs = 10 # short training period\n","total_epochs =  initial_epochs + fine_tune_epochs # total training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yH2Ny71DQh4G","executionInfo":{"status":"aborted","timestamp":1699554891879,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# Create a callback that saves the model's weights as a checkpoint\n","# Checkpoints use less memory and speed up training - can compile model after training\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True, # checkpoints not full model\n","                                                 save_best_only=True,  # save the best model based on what's being monitored\n","                                                 monitor='val_categorical_accuracy',\n","                                                 verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cchom-q9Qh4G","executionInfo":{"status":"aborted","timestamp":1699554891879,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["# second full fine-tune learning\n","history_fine = model.fit(train_ds,\n","                         epochs=total_epochs,\n","                         initial_epoch =  history.epoch[-1],\n","                         validation_data = validation_ds,\n","                         steps_per_epoch = np.ceil(image_count/BATCH_SIZE),\n","                         callbacks=[cp_callback]) # added this callback for checkpointing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S0uyZnvrQh4G","executionInfo":{"status":"aborted","timestamp":1699554891879,"user_tz":480,"elapsed":9,"user":{"displayName":"Chris Bartha","userId":"07409752300144906679"}}},"outputs":[],"source":["acc = history_fine.history['categorical_accuracy']\n","val_acc = history_fine.history['val_categorical_accuracy']\n","\n","loss = history_fine.history['loss']\n","val_loss = history_fine.history['val_loss']\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.ylabel('Accuracy')\n","plt.ylim([min(plt.ylim()),1])\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.ylabel('Cross Entropy')\n","plt.ylim([0,1.0])\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:ABG-cnn_tf230] *","language":"python","name":"conda-env-ABG-cnn_tf230-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}